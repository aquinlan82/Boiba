{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, lrate, loss_fn, in_size, out_size):\n",
    "        \"\"\"\n",
    "        Initializes the layers of your neural network.\n",
    "\n",
    "        @param lrate: learning rate for the model\n",
    "        @param loss_fn: A loss function defined as follows:\n",
    "            @param yhat - an (N,out_size) Tensor\n",
    "            @param y - an (N,) Tensor\n",
    "            @return l(x,y) an () Tensor that is the mean loss\n",
    "        @param in_size: input dimension\n",
    "        @param out_size: output dimension\n",
    "\n",
    "        For Part 1 the network should have the following architecture (in terms of hidden units):\n",
    "\n",
    "        in_size -> 32 ->  out_size\n",
    "\n",
    "        We recommend setting lrate to 0.01 for part 1.\n",
    "\n",
    "        \"\"\"\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.loss = loss_fn\n",
    "        self.learning_rate = lrate\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3, 18, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(18 * 16 * 16, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 2)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr=lrate, weight_decay=0.01)\n",
    "\n",
    "    def set_parameters(self, params):\n",
    "        \"\"\" Sets the parameters of your network.\n",
    "\n",
    "        @param params: a list of tensors containing all parameters of the network\n",
    "        \"\"\"\n",
    "        self.parameters = params\n",
    "\n",
    "    def get_parameters(self):\n",
    "        \"\"\" Gets the parameters of your network.\n",
    "\n",
    "        @return params: a list of tensors containing all parameters of the network\n",
    "        \"\"\"\n",
    "        return self.parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Performs a forward pass through your neural net (evaluates f(x)).\n",
    "\n",
    "        @param x: an (N, in_size) Tensor\n",
    "        @return y: an (N, out_size) Tensor of output from the network\n",
    "        \"\"\"\n",
    "        x = x.reshape(len(x),3,32,32)\n",
    "        x = F.leaky_relu_(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 18 * 16 * 16)\n",
    "        x = F.leaky_relu_(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return (x)\n",
    "\n",
    "\n",
    "\n",
    "    def step(self, x,y):\n",
    "        \"\"\"\n",
    "        Performs one gradient step through a batch of data x with labels y.\n",
    "\n",
    "        @param x: an (N, in_size) Tensor\n",
    "        @param y: an (N,) Tensor\n",
    "        @return L: total empirical risk (mean of losses) at this timestep as a float\n",
    "        \"\"\"\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.forward(x)\n",
    "        loss = self.loss(output, y)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "def fit(train_set,train_labels,dev_set,n_iter,batch_size=100):\n",
    "    \"\"\" Make NeuralNet object 'net' and use net.step() to train a neural net\n",
    "    and net(x) to evaluate the neural net.\n",
    "\n",
    "    @param train_set: an (N, in_size) Tensor\n",
    "    @param train_labels: an (N,) Tensor\n",
    "    @param dev_set: an (M,) Tensor\n",
    "    @param n_iter: an int, the number of iterations of training\n",
    "    @param batch_size: size of each batch to train on. (default 100)\n",
    "\n",
    "    This method _must_ work for arbitrary M and N.\n",
    "\n",
    "    @return losses: array of total loss at the beginning and after each iteration.\n",
    "            Ensure that len(losses) == n_iter.\n",
    "    @return yhats: an (M,) NumPy array of binary labels for dev_set\n",
    "    @return net: a NeuralNet object\n",
    "    \"\"\"\n",
    "    net = NeuralNet(0.07, torch.nn.CrossEntropyLoss(), 3072, 2)\n",
    "\n",
    "    #processing\n",
    "    m = torch.mean(train_set)\n",
    "    s = torch.std(train_set)\n",
    "    train_set = (train_set - m) / s\n",
    "\n",
    "    m = torch.mean(dev_set)\n",
    "    s = torch.std(dev_set)\n",
    "    dev_set = (dev_set - m) / s\n",
    "\n",
    "\n",
    "    #training\n",
    "    losses = []\n",
    "    epoch_count = 0\n",
    "    for batch_index in range(0, min(len(train_set)-batch_size, 10000), batch_size):\n",
    "        epoch_count = epoch_count + 1\n",
    "        #print(\"Batch #\", epoch_count, \"/\", math.floor(len(train_set) / batch_size))\n",
    "        for i in range(min(n_iter, 10)):\n",
    "            batch = train_set[batch_index:batch_index + batch_size]\n",
    "            labels = train_labels[batch_index:batch_index + batch_size]\n",
    "            losses.append(net.step(batch, labels))\n",
    "\n",
    "    print(\"done training\")\n",
    "\n",
    "    #classification\n",
    "    scores = net.forward(dev_set)\n",
    "    labels = []\n",
    "    for tensor in scores:\n",
    "        first_score = list(tensor)[0].item()\n",
    "        second_score = list(tensor)[1].item()\n",
    "        if first_score > second_score:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "\n",
    "    return losses, labels, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be8395a0f444d4ce60697ffe568eaaefe4ac0b6a817eb76746d19eb411a6fd58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
